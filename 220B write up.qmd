---
title: "Factors in COVID-19 Diagnosis"
format:
  html:
    toc: true
    theme: solar
    toc-location: left
    html-math-method: katex
    css: styles.css
    fontsize: 1.1em
    smooth-scroll: true
    comments:
      hypothesis: 
        theme: clean

editor: visual
---

```{r, echo=FALSE}
library(knitr)

```

## Executive Summary

The purpose of this report is to address two topics: (1) The association between COVID-19 vaccination and infection. Does this association depend on demographics. (2) Make predictions for COVID-19 infection using laboratory tests and demographic variables. There is a complication as not every data entry has all the laboratory tests. Imputation methods are implemented to address the missing data.


Conclusion: 



## Introduction

The COVID-19 pandemic has changed everyone's life these past four years. The very first COVID case in the US was found in the Seattle area, where I was studying at the time. It was an experience to say at the least to be part of that ground zero COVID moment. 

Here is a news report from that moment in time:

<iframe width="560" height="315" src="https://www.youtube.com/embed/FMc280EtXxs?si=qhrqFArvQboAPvui" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

After a couple years, the medical professionals were able to develop vaccinations for COVID-19. However, there were still a surge of COVID cases from time to time. It would be an interesting and important to study if there is an association between the newly infected and their vaccination status, as well as other variables that is available. 

The data set contains 608 observations. Each observation contains infection status, vaccination status, demographic variables(gender, race, and age). As mentioned above, there are laboratory tests available for certain observations. The data is provided to me, and I don't have a full understanding of how the data is collected, however, it would be safe to speculate that they were collected in a place like a hospital and such.


There are two topics that this report is aiming to address: 

(1) The association between COVID-19 vaccination and infection. Does this association depend on demographics



(2) The relationship between COVID-19 infection and vaccination status,laboratory tests and demographic variables. Two models will be presented based on how much information was used. A assessment of the model performances will also be presented at the end. 



## Methods

### Topic 1: 

To investigate the association between COVID-19 infection and vaccination can be done by checking independence of these two variables. Then the independence can be further tested by breaking the samples into different groups based on gender, race or age. 


A Chi-square test is used in this case to study of the rows and columns of a contingency table are statistically associated. The null hypothesis is that the variables are independent, and the alternative is the variables are dependent.


The Pearson statistic is calculated as : $\frac{ \sum (o-e)^2}{e}$

where o is the observed value and e is the expected value. 

The first contingency table only studies the vaccination status and infection status:

```{r, echo=FALSE}

ct1 <- matrix(nrow = 3, ncol = 3)
ct1[,1] <- c("  ","Not infected", "infected")
ct1[,2] <- c("Not Vaccinated", "250","54")

ct1[,3] <- c( "Vaccinated","274","30")

kable(ct1)

```

In this first case, the p-value is calculated to be $0.004791817$, therefore, under the Pearson statistic, the null of independence is rejected. 




To investigate if the association depends on gender, race, age, the same technique is applied for each case: 

*gender*

```{r, echo=FALSE}

ct1 <- matrix(nrow = 3, ncol = 3)
ct1[,1] <- c("  ","Not infected", "infected")
ct1[,2] <- c("Female", "267","32")

ct1[,3] <- c( "Male","257","52")

kable(ct1)

```

The Pearson Statistic is calculated to be 4.789, and the p value equals to *0.028*. Therefore, under the Pearson statistic,at the 5% significance level, the null of independence is rejected. 



*Race*

```{r, echo=FALSE}

ct2 <- matrix(nrow = 3, ncol = 5)
ct2[,1] <- c("  ","Not infected", "infected")
ct2[,2] <- c("Black", "57","15")

ct2[,3] <- c( "Hispanic","97","14")
ct2[,4] <- c( "Other","58","7")
ct2[,5] <- c( "White","312","48")

kable(ct2)

```


The Pearson Statistic is calculated to be 3.689, and the p value equals to *0.054*. Therefore, under the Pearson statistic,at the 5% significance level, the null of independence failed to be rejected. 



### Topic 2: 

There are 2 models that can be built based on how much information was used. 

1. Build a model based on age, race, vaccinated, and gender, which were all available and there was no missing data. 

A couple of techniques that are used in this model building need to be discussed before presenting the model

**Cross Validation**: 

Cross Validation(CV) is a practice where portions of the data is reserved to test and train the model.The main type of CV used in this project is called K fold CV.

K fold CV is a technique that divides data into K folds of equal sizes. One fold is used as a validation set, and the rest are used to train the model. Repeat this step for K times, where each fold is used as a validation fold. Take the average of the prediction errors.

K will be set to 10 in this project. The main use of CV for this project is used with LASSO method(detailed explanation in the following section)


**Logistic Regression**: 

Logistic Regression is a form of a Generalized Linear Model(GLM). The GLM generalizes linear regression by allowing the linear model to be related to the response variable via a link function. 

A GLM contains 3 components: 

Random Component: This refers to the probability distribution of the response variable(Y)

Systematic Component: Combination of linear predictors $\beta_0 +\beta_1x_{1} + \beta_2x_{2} +...\beta_px_{p}$

Link Function: link between random and systematic components. In this case, it's the logit function.

Logistic Regression estimates the probability of an event occurring, in this case, infection, based on given a set of independent variables(demographic variable and lab tests). 

Once the probabilities are estimated, there will be a threshold that needs to be determined. For the probabilities less than that threshold, it will be set to negative, anything above the threshold will be set to positive. In the context of this problem, it will be the COVID diagnosis. 


**LASSO Regression**

Variable selection technique, which will remove the insignificant variable to ensure model simplicity. The method of choice is called the LASSO method. The LASSO method performs both variable selection and regularization in order to improve the model and interpretability. Mathematically, it's similar to LS method :

$min_{\beta} [y - f(x,\beta)]^2 + \lambda \sum |\beta|$, Where $\lambda$ is the penalty term.

The main effect of this method is that some of the betas are shrunk exactly to zero, resulting in a simpler model.


To perform some EDA before fitting the model: 

(a) A initial look at the data frame. Race, vaccinated and gender will be coded as factors, the infection status(y) is coded as 0 if negative and 1 if positive


(b) A initial look at the distribution of the infected. (Negative is coded as 0). Out of everyone who is tested, an overwhelming majority have a negative test result.

![](hist1(limited).png)


It is a good practice to perform data splitting before building the model. In this case, the data frame will be separated based on the outcome variable y. Then take a 20% of random samples from the positive results and a 20% of random samples from the negative results as the testing set. The remaining will be the training set. This division will ensure there are positive cases in both training and testing, since there an overwhelming majority have a negative test result.


A model is built based on the training data with the implementation of CV and LASSO to reduce the model. 

![](LASSO_limited.png)

A prediction is made using the model and the training data. A detailed presentation and comparison between the models is presented in the next section. 






2. Build a model based when demographic variables (age, race, vaccinated, and gender) and laboratory tests are available

As mentioned above, the lab test results are not available for all observations due to practical reasons. Therefore, an imputation of the missing data will be performed. The first step is to investigate which tests have missing values: 


![](missing_lab.png)
**It is important to note that the distribution of all of these lab tests are normalized to have a mean 0 and standard deviation 1.**


An imputation procedure called multiple imputation will be implemented to replace the missing data, then there will be a model fitting and selection procedure. 

A detailed explanation of the impuation and model fitting techniques used in this project will be presented below: 

**Multiple Imputation**

Multiple imputation is among the more powerful (basic) techniques for handling missing data. It follows a
multi-step procedure. First, m different sets of imputed values are generated (usually m ∈ {5, 6, · · · , 20})
through some appropriate method. Multivariate Gaussian imputation, where we let missing values be drawn
from some multivariate Gaussian conditional on the observed data, is a popular choice. This process results
in m complete datasets.
Next, each of the m datasets are separately analyzed. This analysis can be done using whatever procedure is
of interest – regression, ANOVA, etc. – and will yield m sets of parameter and error estimates.
Finally, the parameter estimates from each of the m datasets are pooled to construct aggregate estimates.
Parameter estimates can simply be replaced by the mean estimate across the m datasts. 


**Step wise Selection**

Step-by-step iterative construction of a regression model that involves the selection of independent variables to be used in a final model. It involves adding or removing potential explanatory variables in succession and testing for statistical significance after each iteration.



In this project, a single round of multiple imputation and variable selection will be performed.All the missing data will be sampled from a standard normal distribution.


A GLM model with all the covariates is fitted, then a step function is used to produce the following: 

![](step_output.png)

The step function help reducing the model in a faster rate. However, it is not the best model selection method. After certain number of steps, a LASSO regression will be fitted to further reduce the model:

![](LASSO.png)
![](signle_round.png)

These are the variables that were determined as significant using LASSO. 

The procedure then becomes impute the missing data for these variables, fit the model and save the coefficients. This procedure will be repeated 5 times and the coefficients of the final model will be the average of the 5 sets of coefficients: 

![](final_coef.png)


The prediction is then made using the final model and the testing data. As mentioned above, the logistic model predicts the probability of a binary response. Therefore, a threshold is necessary to convert the predicted probabilities to binary responses. 

A assessment of the thresholds is performed: 

![](threshold.png)

The threshold is set to 1.212678e-01 in this project to create a balance between specificity and sensitivity.

Once the threshold is determined, prediction using the testing data and the two models are made. A detailed look at their performances is presented in the next section


## Results, conclusions and recommendations

**Results**





*To address the second topic:*

To best present the results visually, a confusion and a ROC curve plot are construed 

Model w/o lab tests: 

![](CM_limited.png)


![](ROC_limited.png)

Model with lab tests: 



![](CM.png)

![](ROC.png)

First examine the confusion matrices, the model with the lab tests performed better since it has a better true positive and true negative rate. The ROC curves also showed that the model with lab tests performed better.(The closer the ROC curve is to the upper corner, the higher the accuracy is)


Overall, the model with the lab tests performed better when it comes to prediction at this specific threshold. 


**Recommendations**

Under dispersion 

Threshold chosen arbitrarily, 





## Appendix

## References/ Citations

[GLM](https://online.stat.psu.edu/stat504/lesson/beyond-logistic-regression-generalized-linear-models-glm)

[Step Selection](https://www.investopedia.com/terms/s/stepwise-regression.asp#:~:text=Stepwise%20regression%20is%20the%20step,statistical%20significance%20after%20each%20iteration.)

[Multiple Imputation] 220B Section Slides 8
